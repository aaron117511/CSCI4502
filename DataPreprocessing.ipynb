{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "860c67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0564e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NULL values\n",
      "Number of identified outliers: 6/545\n",
      "Dataset size after outlier removal: 539\n",
      "       price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
      "0    4200000  5500         3          1        2         1          0   \n",
      "1    6720000  5020         3          1        4         1          0   \n",
      "2    2660000  2800         3          1        1         1          0   \n",
      "3    4830000  4815         2          1        1         1          0   \n",
      "4    3360000  4120         2          1        2         1          0   \n",
      "..       ...   ...       ...        ...      ...       ...        ...   \n",
      "534  7560000  6000         3          2        3         1          0   \n",
      "535  5250000  8520         3          1        1         1          0   \n",
      "536  3150000  1650         3          1        2         0          0   \n",
      "537  3990000  4100         4          1        1         0          0   \n",
      "538  7350000  6000         3          1        2         1          0   \n",
      "\n",
      "     basement  hotwaterheating  airconditioning  parking  prefarea  \n",
      "0           0                0                1        0         0  \n",
      "1           0                0                1        0         1  \n",
      "2           0                0                0        0         0  \n",
      "3           0                0                1        0         1  \n",
      "4           0                0                0        0         0  \n",
      "..        ...              ...              ...      ...       ...  \n",
      "534         0                0                1        0         0  \n",
      "535         0                0                1        2         0  \n",
      "536         1                0                0        0         0  \n",
      "537         1                0                0        0         0  \n",
      "538         0                0                1        1         0  \n",
      "\n",
      "[539 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data.csv') # import the data\n",
    "data\n",
    "\n",
    "# check for NULL values and if there are NULL values print the quantity\n",
    "if not data.isnull().values.any():\n",
    "    print('No NULL values')\n",
    "else:\n",
    "    cnt = data.isnull().sum()\n",
    "    print('Number of NULL values: ' + str(cnt))\n",
    "encodedData = pd.DataFrame(data)\n",
    "encodedData['mainroad'] = encodedData['mainroad'].map({'yes': int(1) , 'no': int(0)})\n",
    "encodedData['guestroom'] = encodedData['guestroom'].map({'yes': 1 , 'no': 0})\n",
    "encodedData['basement'] = encodedData['basement'].map({'yes': 1 , 'no': 0})\n",
    "encodedData['hotwaterheating'] = encodedData['hotwaterheating'].map({'yes': 1 , 'no': 0})\n",
    "encodedData['airconditioning'] = encodedData['airconditioning'].map({'yes': 1 , 'no': 0})\n",
    "encodedData['prefarea'] = encodedData['prefarea'].map({'yes': 1 , 'no': 0})\n",
    "encodedData = pd.get_dummies(encodedData)\n",
    "# Shuffle data\n",
    "shuffledData = encodedData.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Ensure all data is numeric and there are no missing values\n",
    "numericData = shuffledData.select_dtypes(include=[np.number]).dropna()\n",
    "numericData_np = numericData.to_numpy()\n",
    "\n",
    "# Multivariate Outlier Detection using Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.01)\n",
    "outliers = iso_forest.fit_predict(numericData_np)\n",
    "outlier_indices = (outliers == -1)\n",
    "print(f'Number of identified outliers: {outlier_indices.sum()}/{len(numericData)}')\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "numericData_clean = numericData[~outlier_indices]\n",
    "numericData_clean.reset_index(drop=True, inplace=True)\n",
    "print(f'Dataset size after outlier removal: {numericData_clean.shape[0]}')\n",
    "\n",
    "# Optionally, view the cleaned data\n",
    "print(numericData_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0123525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=numericData_clean.sample(frac=0.9,random_state=90)\n",
    "test1=numericData_clean.drop(train1.index)\n",
    "train2=numericData_clean.sample(frac=0.9,random_state=80)\n",
    "test2=numericData_clean.drop(train2.index)\n",
    "train3=numericData_clean.sample(frac=0.9,random_state=70)\n",
    "test3=numericData_clean.drop(train3.index)\n",
    "train4=numericData_clean.sample(frac=0.9,random_state=60)\n",
    "test4=numericData_clean.drop(train4.index)\n",
    "train5=numericData_clean.sample(frac=0.9,random_state=50)\n",
    "test5=numericData_clean.drop(train5.index)\n",
    "train6=numericData_clean.sample(frac=0.9,random_state=40)\n",
    "test6=numericData_clean.drop(train6.index)\n",
    "train7=numericData_clean.sample(frac=0.9,random_state=30)\n",
    "test7=numericData_clean.drop(train7.index)\n",
    "train8=numericData_clean.sample(frac=0.9,random_state=20)\n",
    "test8=numericData_clean.drop(train8.index)\n",
    "train9=numericData_clean.sample(frac=0.9,random_state=10)\n",
    "test9=numericData_clean.drop(train9.index)\n",
    "train10=numericData_clean.sample(frac=0.9,random_state=0)\n",
    "test10=numericData_clean.drop(train10.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03369676",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.to_csv('data/train1.csv')\n",
    "test1.to_csv('data/test1.csv')\n",
    "train2.to_csv('data/train2.csv')\n",
    "test2.to_csv('data/test2.csv')\n",
    "train3.to_csv('data/train3.csv')\n",
    "test3.to_csv('data/test3.csv')\n",
    "train4.to_csv('data/train4.csv')\n",
    "test4.to_csv('data/test4.csv')\n",
    "train5.to_csv('data/train5.csv')\n",
    "test5.to_csv('data/test5.csv')\n",
    "train6.to_csv('data/train6.csv')\n",
    "test6.to_csv('data/test6.csv')\n",
    "train7.to_csv('data/train7.csv')\n",
    "test7.to_csv('data/test7.csv')\n",
    "train8.to_csv('data/train8.csv')\n",
    "test8.to_csv('data/test8.csv')\n",
    "train9.to_csv('data/train9.csv')\n",
    "test9.to_csv('data/test9.csv')\n",
    "train10.to_csv('data/train10.csv')\n",
    "test10.to_csv('data/test10.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
